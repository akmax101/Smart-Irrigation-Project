{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                  \n",
    "import numpy as np          \n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from tqdm import tqdm      \n",
    "TRAIN_DIR = 'C:\\\\Users\\\\hp\\\\Desktop\\\\web login\\\\New folder\\\\dataset'\n",
    "\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img[:6]\n",
    "    if word_label == 'cattle': return [1,0]\n",
    "    else:\n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        try:\n",
    "            label = label_img(img)\n",
    "            path = os.path.join(TRAIN_DIR,img)\n",
    "            img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "            training_data.append([np.array(img),np.array(label)])\n",
    "        except:\n",
    "            pass\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76  52 197 ... 240 249 252]\n",
      " [ 76  52 199 ... 246 252 255]\n",
      " [ 80  55 184 ... 246 253 255]\n",
      " ...\n",
      " [194 193 161 ...  43  42  45]\n",
      " [189 170 179 ...  32  33  35]\n",
      " [170 157 170 ...  26  32  25]]\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('train_data.npy',allow_pickle=True)\n",
    "#train_data = create_train_data()\n",
    "print((train_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 22:16:15.113828  4740 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1129 22:16:15.113828  4740 deprecation.py:506] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\initializations.py:119: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1129 22:16:15.129450  4740 deprecation.py:323] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "W1129 22:16:15.176314  4740 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\layers\\conv.py:552: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1129 22:16:15.285662  4740 deprecation.py:506] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1129 22:16:15.348148  4740 deprecation.py:506] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\layers\\core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1129 22:16:15.410633  4740 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W1129 22:16:15.410633  4740 deprecation.py:506] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1129 22:16:15.519984  4740 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W1129 22:16:15.598109  4740 deprecation.py:323] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1129 22:16:16.098003  4740 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\DL_ENV\\lib\\site-packages\\tflearn\\helpers\\trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n",
      "True ll\n",
      "[[[225 227 229]\n",
      "  [227 227 229]\n",
      "  [228 228 228]\n",
      "  ...\n",
      "  [126 126 144]\n",
      "  [124 126 144]\n",
      "  [124 126 144]]\n",
      "\n",
      " [[224 226 228]\n",
      "  [226 226 228]\n",
      "  [227 227 227]\n",
      "  ...\n",
      "  [126 126 144]\n",
      "  [124 126 144]\n",
      "  [124 126 144]]\n",
      "\n",
      " [[222 224 224]\n",
      "  [223 223 223]\n",
      "  [222 222 222]\n",
      "  ...\n",
      "  [127 125 142]\n",
      "  [126 127 143]\n",
      "  [127 128 144]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[149 157 166]\n",
      "  [150 157 168]\n",
      "  [151 158 171]\n",
      "  ...\n",
      "  [ 39  44 110]\n",
      "  [ 38  45 110]\n",
      "  [ 37  44 109]]\n",
      "\n",
      " [[150 157 170]\n",
      "  [150 156 172]\n",
      "  [152 158 175]\n",
      "  ...\n",
      "  [ 42  48 111]\n",
      "  [ 40  46 108]\n",
      "  [ 36  42 104]]\n",
      "\n",
      " [[150 157 170]\n",
      "  [150 156 172]\n",
      "  [152 158 175]\n",
      "  ...\n",
      "  [ 44  50 113]\n",
      "  [ 40  46 108]\n",
      "  [ 34  40 102]]]\n",
      "cattle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "key = cv2. waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "check, frame = webcam.read()\n",
    "print(check,\"ll\") #prints true as long as the webcam is running\n",
    "print(frame) #prints matrix values of each framecd \n",
    "cv2.imshow(\"Capturing\", frame)\n",
    "cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "webcam.release()\n",
    "img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "cv2.waitKey(1650)\n",
    "cv2.destroyAllWindows()\n",
    "path=\"E:\\\\web login\\\\New folder\\\\dataset\\\\cattle122.jpeg\"\n",
    "#path=\"C:\\\\Users\\\\hp\\\\Documents\\\\saved_img.jpg\"\n",
    "img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "x=model.predict(img.reshape(-1,50,50,1))\n",
    "s=\"not cattle\"\n",
    "if(x[0][0]>x[0][1]):\n",
    "    s=\"cattle\"\n",
    "    print(\"cattle\")\n",
    "else:\n",
    "    print(\"not cattle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"code\":\"200 OK\",\"total-messages-sent\":1,\"req-type\":\"post\",\"remaining-sms\":22,\"message\":\"Campaign sent successfully.\",\"usetype\":\"stage\",\"balacne\":\"0\",\"status\":\"success\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "URL = 'https://www.way2sms.com/api/v1/sendCampaign'\n",
    "\n",
    "# get request\n",
    "def sendPostRequest(reqUrl, apiKey, secretKey, useType, phoneNo, senderId, textMessage):\n",
    "  req_params = {\n",
    "  'apikey':\"LD86DCYCTZTZJD18M074LIVISOSH9TPZ\",\n",
    "  'secret':\"MUDJ7EAM6696ISV4\",\n",
    "  'usetype':'stage',\n",
    "  'phone': \"8299159085\",\n",
    "  'message':\"Cattle spotted in farm\",\n",
    "  'senderid':\"Dharmesh\"\n",
    "  }\n",
    "  return requests.post(reqUrl, req_params)\n",
    "if s==\"cattle\":\n",
    "    response = sendPostRequest(URL, 'provided-api-key', 'provided-secret',\n",
    "                           'prod/stage', 'valid-to-mobile',\n",
    "                           'active-sender-id', 'message-text' )\n",
    "\n",
    "# print response if you want\n",
    "print (response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3809  | total loss: 0.01132 | time: 33.537s\n",
      "| Adam | epoch: 015 | loss: 0.01132 - acc: 0.9965 -- iter: 8064/8099\n",
      "Training Step: 3810  | total loss: 0.01326 | time: 34.839s\n",
      "| Adam | epoch: 015 | loss: 0.01326 - acc: 0.9953 | val_loss: 0.39265 - val_acc: 0.9260 -- iter: 8099/8099\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=15, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
